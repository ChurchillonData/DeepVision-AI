{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17eb788a-8c04-47da-a15b-f97a5a00a14f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - pytorch\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install pytorch torchvision torchaudio cpuonly -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c731d0ed-c084-475f-a653-2aa94af3552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f66f984-7bcf-44ac-bd03-3730122da3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.classes = [cls for cls in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, cls))] \n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for idx, class_name in enumerate(self.classes):\n",
    "            class_dir = os.path.join(data_dir, class_name)\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                img_path = os.path.join(class_dir, img_name)\n",
    "                if os.path.isfile(img_path):  \n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.labels.append(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")  \n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1fe30ef-09d1-45b7-8560-cdd360e014b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations for training and validation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fce4ff9a-4396-464f-8d5f-1a5d00dca6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "train_dir = \"D:\\\\BODY\\\\Academia_Lboro\\\\AI & ML\\\\coursework_task01_imageset\\\\imageset\\\\train\"  \n",
    "val_dir = \"D:\\\\BODY\\\\Academia_Lboro\\\\AI & ML\\\\coursework_task01_imageset\\\\imageset\\\\val\"  \n",
    "\n",
    "# Create datasets\n",
    "train_dataset = ImageDataset(train_dir, transform=train_transform)\n",
    "val_dataset = ImageDataset(val_dir, transform=val_transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05046fd0-361b-400b-90e2-c7e0576a9625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MY PC\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\MY PC\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained ResNet18 model\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Replace the final fully connected layer for your number of classes\n",
    "num_classes = len(train_dataset.classes)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Move the model to the device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2ee1062-12a2-4f24-accb-9f840dd68c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f704cde7-3363-4757-b199-9c59e5e136e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.8353, Accuracy: 74.21%\n",
      "Validation Loss: 0.6346, Validation Accuracy: 79.85%\n",
      "Epoch [2/10], Loss: 0.6008, Accuracy: 81.19%\n",
      "Validation Loss: 0.7755, Validation Accuracy: 77.68%\n",
      "Epoch [3/10], Loss: 0.4960, Accuracy: 84.48%\n",
      "Validation Loss: 0.5437, Validation Accuracy: 83.54%\n",
      "Epoch [4/10], Loss: 0.4133, Accuracy: 86.58%\n",
      "Validation Loss: 0.6269, Validation Accuracy: 81.94%\n",
      "Epoch [5/10], Loss: 0.3904, Accuracy: 87.68%\n",
      "Validation Loss: 0.4779, Validation Accuracy: 86.04%\n",
      "Epoch [6/10], Loss: 0.3380, Accuracy: 89.10%\n",
      "Validation Loss: 0.6290, Validation Accuracy: 83.18%\n",
      "Epoch [7/10], Loss: 0.3346, Accuracy: 89.11%\n",
      "Validation Loss: 0.5324, Validation Accuracy: 84.56%\n",
      "Epoch [8/10], Loss: 0.2875, Accuracy: 90.69%\n",
      "Validation Loss: 0.4688, Validation Accuracy: 86.01%\n",
      "Epoch [9/10], Loss: 0.2735, Accuracy: 90.96%\n",
      "Validation Loss: 0.4730, Validation Accuracy: 86.68%\n",
      "Epoch [10/10], Loss: 0.2410, Accuracy: 92.22%\n",
      "Validation Loss: 0.4774, Validation Accuracy: 86.19%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    # Print training statistics\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = 100.0 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    # Print validation statistics\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_acc = 100.0 * correct / total\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cf373e4-3f2b-4e82-a135-660a6fb72be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"D:\\\\BODY\\\\Academia_Lboro\\\\AI & ML\\\\coursework_task01_imageset\\\\imageset\\\\image_classification_resnet18.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82454570-6bc8-4fb3-9b23-7b2cb2ba68c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: n03000684\n"
     ]
    }
   ],
   "source": [
    "def classify_test_image(model, image_path, transform, class_names, device):\n",
    "    # Load and preprocess the image\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0) \n",
    "    image = image.to(device)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        _, predicted = output.max(1)\n",
    "        predicted_class = class_names[predicted.item()]\n",
    "\n",
    "    return predicted_class\n",
    "\n",
    "# Example usage\n",
    "test_image_path = \"D:\\\\BODY\\\\Academia_Lboro\\\\AI & ML\\\\coursework_task01_imageset\\\\imageset\\\\val\\\\n03000684\\\\ILSVRC2012_val_00045501.JPEG\"  #test image\n",
    "predicted_class = classify_test_image(model, test_image_path, val_transform, train_dataset.classes, device)\n",
    "print(f\"Predicted Class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84538b95-c763-4f86-b0c5-4cbbeab52223",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
